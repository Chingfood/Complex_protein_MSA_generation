#!/bin/bash

# ./run.sh uniclust30_2017_10_a3m.ffdata 2017_10

a3m_ffindex=$1
version=$2

#a3m_ffindex=uniclust30_${version}_a3m.ffdata
uniprot_ID_list=uniprot_ID_list_${version}
xref_list_folder=xref_list_${version}
xref_batch_folder=xref_batch_${version}
xref_folder=xref_${version}
merged_xref_list=merged_xref_list_${version}
contig_list=contig_list_${version}
wgs_list=wgs_list_${version}
CDS_folder=CDS_folder_${version}
loc_folder=loc_folder_${version}
id_loc=id_loc_${version}
mkdir -p $xref_list_folder $xref_batch_folder $xref_folder $CDS_folder $loc_folder

# extract IDs in our database
echo "Collecting Uniprot IDs"
python extract_ID.py $a3m_ffindex $uniprot_ID_list

num_query=`wc -l $uniprot_ID_list | cut -d' ' -f1`
echo "We have $num_query queries in total"
# 97 884 147 in total
source=UniProtKB/TrEMBL
echo "Downloading $source entries"
from=0;	to=$num_query;	num_thread=10	# left-close, right-open
#from=0;	to=10000;	num_thread=20	# left-close, right-open
#i=0;	k=7000000;	from=$(($i*$k)); to=$(($(($i+1))*$k))
./download_xref.sh $uniprot_ID_list $source $xref_list_folder $from $to $num_thread

source=UniProtKB/Swiss-Prot
echo "Downloading $source entries"
./download_xref_batch.sh $source $xref_batch_folder

# To merge downloaded files if needed
# copy batch to the proper folder
cp $xref_list_folder/* $xref_folder
cp $xref_batch_folder/* $xref_folder
echo "merging lists"
python merge_xref_list.py $xref_folder $merged_xref_list
echo "coverage should be 0~$num_query"

# To verify data class
echo "verifying data"
cut -f 5 $merged_xref_list > tmp_contig
cut -f 4 $merged_xref_list > tmp_coding
wc -l tmp_contig tmp_coding
python -c "from enaBrowserTools.python.utils import is_wgs_sequence, is_sequence
with open('tmp_contig', 'r') as f: assert (is_sequence(_) or is_wgs_sequence(_) for _ in [l[:-1] for l in set(f)])" &
python -c "from enaBrowserTools.python.utils import is_coding
with open('tmp_coding', 'r') as f: assert all(is_coding(_) for _ in f.read().strip().split())" &
wait
echo "verified"

# To separate contig and wgs
echo "separating contig and wgs"
python extract_contig_wgs_ID.py tmp_contig $contig_list $wgs_list
wc -l $contig_list $wgs_list
rm -f tmp_contig tmp_coding

ID_list=$contig_list;	outfolder=$CDS_folder/contig_
num_query=`wc -l $ID_list | cut -d' ' -f1`
echo "We have $num_query queries in total"
# 9 105 361
from=0;	to=$num_query;	num_thread=10	# left-close, right-open
#from=0;	to=121;	num_thread=10	# left-close, right-open
./download_contig.sh $ID_list $outfolder $from $to $num_thread
wait

ID_list=$wgs_list;		outfolder=$CDS_folder/wgs_
num_query=`wc -l $ID_list | cut -d' ' -f1`
echo "We have $num_query queries in total"
# 16 704
from=1;	to=$num_query;	num_thread=10	# left-close, right-open
#from=1;	to=26;	num_thread=10	# left-close, right-open
./download_contig.sh $ID_list $outfolder $from $to $num_thread
wait

echo "extracting CDS from raw data"
cut -f 2,4 $merged_xref_list > tmp_merged_xref_list
python extract_CDS_parallel.py tmp_merged_xref_list $CDS_folder $loc_folder 2> extract_CDS_$version.log
rm tmp_merged_xref_list

echo "generating id_loc file"
python genFile.py $loc_folder $id_loc
